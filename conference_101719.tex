\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subfig}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{diagbox}
\usepackage{footnote}
\usepackage{bbding} %\Checkmark \XSolid
% to be able to draw some self-contained figs
\usepackage{tikz}
% inlined bib file
\usepackage{filecontents}
\usepackage{flushend}
\usepackage{color}

\definecolor{revision}{rgb}{0,0,255}

\algrenewcommand\textproc{}% Used to be \textsc
\newcommand{\pushcode}[1][1]{\hskip\dimexpr#1\algorithmicindent\relax}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Lock Violation for Fault-tolerant Distributed Database System}


\author{\IEEEauthorblockN{Hua Guo}
\IEEEauthorblockA{\textit{School of Information} \\
\textit{Renmin University of China}\\
Beijing, China \\
guohua2016@ruc.edu.cn}
\and
\IEEEauthorblockN{Xuan Zhou}
\IEEEauthorblockA{\textit{School of Data Science And Engineering} \\
\textit{East China Normal University}\\
Shanghai, China \\
xzhou@dase.ecnu.edu.cn}
\and
\IEEEauthorblockN{Le Cai}
\IEEEauthorblockA{
%\textit{} \\
\textit{Alibaba Group}\\
San Mateo, CA, US \\
le.cai@alibaba-inc.com}
}

\maketitle

\begin{abstract}
Modern distributed database systems scale horizontally by sharding its data across a large number of nodes.
To achieve fault tolerance, most such systems build their transactional layers on a replication layer,
employing a consensus protocol to ensure data consistency.
Synchronization among replicated state machines thus becomes a significant overhead of transaction processing.
Without careful design, synchronization could amplify transactions' lock duration and impair the system's scalability.
Speculative techniques, such as Controlled Lock Violation (CLV) and Early Lock Release (ELR), prove useful in shortening lock critical path and boosting transaction processing performance.
An intuitive idea is to use these techniques to optimize geo-replicated distributed databases(GDDB).
This paper shows that a naive application of speculation is often unhelpful in a distributed environment.
Instead, we introduce Distributed Lock Violation (DLV), a specialized speculative technique for geo-replicated distributed databases.
DLV can achieve good performance without incurring severe side effects.
\end{abstract}

\begin{IEEEkeywords}
Database System, Distributed Transaction, Locking, High Availability
\end{IEEEkeywords}

\section{Introduction}

Modern distributed database systems scale out by partitioning data across multiple servers,
so as to increase throughput by running transactions in parallel.
When a transaction needs to access multiple partitions, it has to employ a coordination protocol to ensure atomicity.
Such distributed transactions may lead to significant performance degradation, mainly due to the two reasons\cite{Calvin:conf/sigmod/ThomsonDWRSA12}:
1. Coordinated commit requires a chatty protocol, such as Two-Phase Commit (2PC), which introduces tremendous network overheads;
2. Message transmission overlaps with the critical path of transaction commit, which worsens the contention among transactions.

These issues can be more severe for geo-replicated databases, which face increased network overheads.
The replication layer of a geo-replicated database often uses a Paxos-like consensus protocol to ensure consistency among replicas.
Replication and consensus introduce an additional amount of message transmission, which further increases the duration of transactions.
To facilitate replication, we usually split data into small chunks and replicate each chunk independently.
If the placement of chunks cannot be predetermined, cross-chunk transactions (rather than cross-partition transactions) all become distributed transactions.
This makes distributed transactions even more inevitable.

\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.7]{figure/architecture.pdf}}
  \caption{Typical architecture of GDDB}
  \label{fig:architecture}
\end{figure}

Fig.~\ref{fig:architecture} presents a typical architecture of a geo-replicated distributed database (GDDB).
Data is partitioned into a number of chunks.
Each chunk is replicated to several Availability Zones (AZ) \cite{Aurora:conf/sigmod/VerbitskiGSCGBM18}.
Among the available zones, the replication layer employs a consensus protocol to shield data consistency.

As discussed in some previous works \cite{Calvin:conf/sigmod/ThomsonDWRSA12}\cite{Tapir:conf/sosp/ZhangSSKP15}\cite{Janus:conf/osdi/MuNLL16},
this architecture has to rely on a two-layer protocol (which integrates the commit protocol and the consensus protocol) to ensure transactions' correctness.
It may fail to scale when confronted with a highly contended workload.


\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.50]{figure/message_flow.pdf}}
  \caption
  {
The DB uses S2PL for concurrency control and 2PC as the commit protocol.
This figure shows the message flow of a transaction commit.
The red lines represent the critical paths of locking.
    }
\label{fig:message_flow}
\end{figure}

Fig.~\ref{fig:message_flow} shows the message flow of a distributed transaction in such an architecture. We assume that
GDDB uses Strict Two-Phase Locking (S2PL) for concurrency control and 2PC as the commit protocol, and the replication layer works over a Wide Area Network (WAN).
When a transaction requests to commit, the \emph{TM (transaction manager)} issues a `prepare' message to each \emph{RM (resource manager)}.
Then, each \emph{RM} replicates its vote (`prepare commit' or `prepare abort') to its replicas through a consensus protocol before it
sends its voting result to \emph{TM}.
After the \emph{TM} collects all the votes from the \emph{RMs}, it first replicates its decision (`commit' or `abort') to its replicas, before broadcasting the decision to all the \emph{RMs}.
%\footnote{Depending on variants of implementations, the TM can choose to persist its decision on its log or not.}
Once a \emph{RM} receives the final decision from the \emph{TM}, it also needs to replicate the decision to the corresponding replicas.
Only at this moment, can the GDDB reach a consensus about commit or abort.
Then, the \emph{RM} can release the locks it had retained over the accessed data.
Finally, \emph{TM} replicate an `end' log to finish the transaction and clean the transaction context.

%change begin
In a replicated DB, if a \emph{RM} releases its locks immediately after receiving the commit message and before persisting its decision, linearizability may not be guaranteed. 
The following is a situation:
(1) A \emph{RM} of a transaction ${T}$ receives a commit message.
(2) The \emph{RM} releases ${T}$'s lock on a tuple ${x}$. Following that,
a second transaction ${R}$ reads ${T}$'s write on ${x}$ and commits successfully.
(3) Before the \emph{RM} persists its commit log, the node it resides on fails. 
(4) After the node recovers, the \emph{RM} re-enters an uncertain state, as it cannot remember it has received a commit message. At this time, as the lock has been released, a third transaction ${S}$ may choose to read an older version of ${x}$, which may lead to violation of linearizability.


Lock duration of transaction commit in such an architecture, i.e., the red line in Fig.~\ref{fig:message_flow}, involves multiple messages round trips over the WAN.
And there was also message between LAN.
Different newtwork environment have different RTT(round trip time).
For exampele, take Alibaba ECS servers as an example.
The RTT between two servers in the same AZ is about 0.12ms and the RTT in the different city of is 1.96ms.
RTT of servers in different city of same continents can be 33.5ms(from Hangzhou to Heyuan).
On different continents, the RTT could be 98.6ms(from Virginia to Frankfurt), 206ms(from Hangzhou to Frankfurt)
It is apparent that geo-replication can remarkably amplify lock duration and worsen the contention among transactions.
Consider that the RRT over a geo-distributed WAN is around 30-200 milliseconds, while a transaction 
This huge difference of RTT let use consider exploit  
speculative technique to reduce lock blocking.

Speculative techniques, such as Early Lock Release (ELR) \cite{EfficientLocking:conf/vldb/KimuraGK12} and Controlled Lock Violation (CLV)
\cite{CLV:conf/sigmod/GraefeLKTV13}, prove to be effective in optimizing centralized transaction processing.
They aim at improving concurrency by excluding data persistence (i.e., logging) from lock duration.
In a GDDB, data synchronization among replicas can be treated as prolonged data persistence, which needs to ship and persist logs on majority of replicas.
This inspires us to exploit speculation to shorten lock duration in GDDB.

However, the application of speculation in a distributed environment is complex.
For instance, when working with 2PC, we need to decide to violate (or release) lock at which phase.
As some previous work suggested \cite{CLV:conf/sigmod/GraefeLKTV13}, lock violation at an early phase may enable a higher degree of concurrency,
while it may face excessive overheads of dependency tracing or cascade abort.
On the contrary, lock violation at a late phase costs less on dependency tracing and cascade abort,
while it may lose opportunity of harnessing more concurrency.
%Another aspect to consider is how locking violation would compose with deadlock handling.
%This area is not well explored.
Moreover, not all transactions can benefit from CLV or ELR, e.g., workload with little conflict.
It is unnecessary and even harmful to apply speculation to all cases.

The contribution of this paper can be summarized as follows:

%{change begin}
1. To the best of our knowledge, this is the first study of lock violation on GDDB.
We found that CLV does not has adequate information
to straightforward extend it to GDDB.
The performance of CLV on GDDB is unknown. 
There are many design choices if we conduct CLV on GDDB.
There is a hole between CLV's centralized database version and its distributed one, especially for GDDB.
Cascade abort, dependency maintaining, deadlock handling, violation timing, and storage implementation, which CLV did not involve, may be considered and examined.
Not all design choices can adapt to the various workload.

2. We propose a technique called Distributed Lock Violation (DLV) to enhance the performance of GDDB.
DLV address several time windows to perform lock violation.
Dependent on violations timing and their characteristic, DLV tries to minimize the penalty of dependency tracing and cascade abort.
We evaluation DLV and get their performance and their application scenarios.
DLV consolidates many disperse lock wait before commit on a final wait before transaction prepared.
It allows dependency maintaining individually in memory on each node and avoid persisting them.
%{change end}

We organized the remainder of this paper as follows.
Section \ref{sec:relate_work} reviews the related work.
In Section \ref{sec:non_strict} we explain lock violation and how to ensure the correctness of distributed transactions in face of lock violation.
Section \ref{sec:implement} introduces our design of DLV.
Section \ref{sec:experiment} evaluates DLV and compares it against other forms of lock violation.
Section \ref{sec:conclusion} concludes this paper.


\section{Relate Work}
\label{sec:relate_work}
%This section introduces the related work of this paper.

\subsection{Transaction Processing on Replicated Databases}


Most replicated databases rely on state-machine replication (SMR) to realize high availability.
SMR often uses a consensus protocol to synchronize replicas.
The synchronization introduces a significant amount of network traffic and becomes a significant overhead of replicated database systems.
Paxos~\cite{Paxos:journals/tocs/Lamport98} is the most well known consensus protocol.
To reach a consensus on a single data update in Paxos, it costs two message round trips, one for choosing a proposal and another for proposing the entry.
Multidecree Paxos\cite{Multidecree:journals/csur/RenesseA15} elects a leader as the only proposer to eliminate the first message round trip.
Raft\cite{Raft:conf/usenix/OngaroO14} is a similar consensus protocol to Paxos.
Modern database systems widely use Raft, as it is more understandable than Paxos.
In Raft, it costs at least one message round trip to reach a consensus.
Google Spanner \cite{Spanner:conf/osdi/CorbettDEFFFGGHHHKKLLMMNQRRSSTWW12},
NuoDB \cite{NuoDB}, CockroachDB \cite{CockroachDB} and TiDB \cite{TiDB} are all geo-replicated DBMSes built upon Paxos or Raft.
They all face heavy costs incurred by data synchronization and consensus.

Previous work has proposed many techniques
to minimize the cost of synchronization.
VoltDB \cite{VoltDB} and Calvin \cite{Calvin:conf/sigmod/ThomsonDWRSA12} employ a deterministic transaction model
to reduce the coordination cost of distributed transactions.
A deterministic scheduler enables active replication, allowing transactions to kick off synchronization at the earliest possible time.
Tapir \cite{Tapir:conf/sosp/ZhangSSKP15} relaxes the replication layer's consistency requirements so that it can reduce the message round trips to reach consensus.
Janus \cite{Janus:conf/osdi/MuNLL16} aims to minimize wide-area message round trips
by consolidating the concurrency control mechanism and the consensus protocol.
It uses deterministic serializable graph tracing to ensure the atomicity of transactions.
In a nutshell, Tapir and Janus both co-designed the transaction and replication layers of distributed databases, so that they only need to incur one wide-area message round trip to commit a transaction.
However, VoltDB, Calvin, Tapir, and Janus all impose strict constraints on implementing the transaction layer, making them incompatible with existing systems, such as Spanner and CockroachDB.
In contrast, our work focuses on the optimization opportunities, in particular lock violation, in a general implementation of geo-replicated distributed databases (GDDB), as depicted in Fig.~\ref{fig:architecture}.
To the best of our knowledge, this area has not been adequately studied.

\subsection{Optimization on Locking based Concurrency Control}
Two-phase locking (2PL) is the most widely used concurrency control mechanism.
As a pessimistic method, 2PL assumes a high likelihood of transaction conflict.
It uses locks to enforce the order of conflicting transactions.
Strict 2PL (S2PL) is a brute force implementation of 2PL.
It requires a transaction to preserve all its lock until it ends.
As S2PL can easily guarantee transactions' recoverability, many databases choose to use it.
When extending S2PL to GDDB, transaction commitment and replication would substantially enlarge the lock holding time,
as the commitment will involve several message round trips. This has been illustrated in Fig.~\ref{fig:message_flow}.

All S2PL implementations adopt a specific approach to resolve deadlocks.
While deadlock detection proves effective in centralized database systems \cite{MySQL}\cite{PostgreSQL}, it is costly in a distributed environment.
In the \emph{no-wait}
\cite{EvaluationOfCC:journals/pvldb/HardingAPS17}
approach, a transaction immediately aborts if it fails to place a lock.
Previous works showed that this is a scalable approach in a distributed environment \cite{EvaluationCC1000Cores:journals/pvldb/YuBPDS14}\cite{EvaluationOfCC:journals/pvldb/HardingAPS17},
as it eliminates blocking completely.
However, it performs poorly when dealing with high-contention workload.
Another approach is \emph{wait-die} \cite{LockNoWait:journals/csur/BernsteinG81}.
It avoids some false-positive aborts encountered by \emph{no-wait} by utilizing timestamps.
The \emph{deadlock detection} approach \cite{LockCC:conf/ds/GrayLPT76} detects deadlock by explicitly tracing wait-for relationship among transactions
In this work, we discuss and evaluate both the wait-die and deadlock detection approaches.
%it is costly in a distributed environment.
%However, deadlock detection in a distributed environment is highly costly, making it the least favorable approach in our case.

Speculation can be used to optimize the performance of locking based concurrency control.
Early lock release (ELR)
\cite{EfficientLocking:conf/vldb/KimuraGK12}
\cite{ELR:dewitt_implementation_1984}
\cite{PS2PL:conf/icdt/Soisalon-SoininenY95}
\cite{Aether:journals/pvldb/JohnsonPSAA10}
\cite{Actor-Oriented-DB:conf/icde/Bernstein18}
is a typical speculative technique.
ELR allows a transaction to release its locks before DB flush its commit log to disk.
It was first proposed by DeWitt et al.\cite{ELR:dewitt_implementation_1984}.
Soisalon-Soininen et al. \cite{PS2PL:conf/icdt/Soisalon-SoininenY95} analyzed its correctness in various settings.
Many other works applied and evaluated ELR in different types of systems
\cite{EfficientLocking:conf/vldb/KimuraGK12}
\cite{Aether:journals/pvldb/JohnsonPSAA10}.
%{change begin}
 \cite{CLV:conf/sigmod/GraefeLKTV13} 
CLV is a competitor of ELR. 
 It is simpler, more robust, and more precise than ELR.
 It allows specific transactions to ignore conflict locks instead of releasing a lock completely.
 ELR can only optimize the two-phase commit's final phase, but CLV can optimize both phases of the two-phase commit.
 CLV is the most related paper of our work.
 Although CLV can adapt to distributed transactions, 
 how to apply CLV to the distributed database is still challenging.
 CLV needs a Register and Report (RARA) approach \cite{HeckatonMVCC:journals/pvldb/LarsonBDFPZ11} to implement the tracer.
 RARA works well on a centralized database. 
 But in a distributed environment, dependency tracing becomes much more costly.
 Cascade abort is another side effect of speculation. 
 It can also lead to severe performance downgrade for distributed databases.
 Handling deadlock in a distributed environment is challenging and costly, and how CLV adapts to deadlocking handling rules is not apparent.
 CLV lacks adequate information on how to flip it from a centralized database to a distributed one. 
 Moreover, the performance of different lock violation timing and their restriction is still unexplored.
 Finally,   the increasing prosperity of fault-tolerant geo-replicated databases for a  has suffered high log replication latency.
 How CLV and other speculation ideas can improve the replicated system is interesting.
%{change end}

There is little research on applying speculation to GDDB, while the potential rewards seem ample. This motivated us to look further into this issue.


\section{Scheduling with Lock Violation}
\label{sec:non_strict}

In the following, we describe the basic idea of applying lock violation to transaction scheduling.
Later, we discuss how to achieve the correctness of lock violation.

\subsection{Preliminaries and Assumptions}
Consider a GDDB, which shards its data by primary keys.
Each shard replicates its data across several remotely located AZs.
Physiological logs, which record row-level write operations, are transmitted among the AZs to keep the data synchronized.
A consensus protocol is used to prevent synchronization from going wrong.
We assume that each data shard is assigned a leader who is responsible for coordinating its synchronization process.
%change begin
We define two types of distributed transactions,  deterministic prepared (DP) transactions and non-deterministic prepared (NDP) transactions.
If a transaction knows that it will not violate serializability before issuing the prepare message it is a DP transaction. Otherwise, it is an NDP transaction. 
In other words, in a DP transaction, if a \emph{RM} receives a prepare message, it knows that other \emph{RM}s will all be prepared.
We can categorize most interactive transactions as DP transactions.
Fig.~\ref{fig:transaction_type} shows the message flow during the commit phase of the two types of transactions.
How DLV applies to DP and NDP transactions would be discussed later.

%We can see that DP transaction costs more message round trips than a NDP transaction.
%In an DP transaction, the $TM$ must explicitly notify the $RM$s to prepare committing.

\begin{figure}[tbp]
    \centering
    \captionsetup[subfigure]{oneside,margin={0.2cm,0cm}}
    \subfloat[NDP transaction, ${RM}$ knows nothing about other ${RM}$'s state when receiving \emph{Prepare}]
        { \includegraphics[scale=1] {figure/transaction_oneshot}  \label{fig:transaction_NDP}  }
    \captionsetup[subfigure]{oneside,margin={0.3cm,0cm}}
    \subfloat[DP transaction, ${RM}$ would be told other ${RM}$'s state when receiving \emph{Prepare}]
        { \includegraphics[scale=1]{figure/transaction_interactive} \label{fig:transaction_DP}}

  \caption{Commit message flows for DP and NDP distributed transactions}
  \label{fig:transaction_type}
\end{figure}


\subsection{Scheduling of Distributed Transactions}
Before presenting the idea of lock violation, we first review the conceptual model of distributed transaction processing,
which has been formalized in previous work, such as \cite{LockNoWait:journals/csur/BernsteinG81}.

\subsubsection{Transaction and Schedule}
Suppose that a distributed database resides on ${n}$ nodes, represented by ${R = \{r_1, r_2, ... r_n\}}$.
A transaction ${T_i}$ runs on ${m}$ of the ${n}$ nodes ($1 \le m \le n$).%, represented by  ${S = \{s_1, s_2, ... s_m\} \subseteq R}$,
The transaction ${T_i}$ is composed of a series of operations,
each of which can be a read or a write or other command operation including abort, commit, etc.
Let ${r_i[x]}$ denote that ${T_i}$ reads the record ${x}$. Let ${w_i[x]}$ denote that ${T_i}$ writes on the record ${x}$.
Let ${c_i}$, ${a_i}$, ${p^c_i}$, ${p^a_i}$ denote the commit, abort, prepare-to-commit and prepare-to-abort operations of ${T_i}$ respectively.


A transaction schedule is a collection ${H = \{h_1, h_2, ..., h_n\}}$.
Each ${h_u}$ is the local schedule of $H$ on the node ${s_u}$, which is a sequential history of operations issued by different transactions.
%For instance, Fig. \ref{fig:strict_example} illustrates a transaction schedule over three nodes.

\subsubsection{Deterministic and Non-deterministic Abort}

Several reasons can cause a transaction to abort. In general, we categorize them as:

1. User requested abort.
These are aborts specified by the program logic (e.g., a transaction requires to abort if it has accessed a non-existent record).

2. System demanded abort.
These are aborts commanded by the database system.
There are several situations that the system will abort a transaction.
For instance, if OCC is applied, a transaction will be aborted in case of potential violation of isolation.
If deadlock detection is applied, to break a wait-for circle,
the scheduler would choose a transaction as a victim to abort.

3. Database node failure.
When a node fails, the system is forced to abort the transactions running on the node. For simplicity, we assume that there are fail-stop failures only.

We call the first two types of abort \emph{deterministic abort} and the last one \emph{non-deterministic abort}.
In a database system, deterministic aborts occur much more frequently than non-deterministic abort.
Therefore, the prices we are willing to pay for the two kinds of abort are very different.

\subsubsection{Dependencies among Transaction}

There are three kinds of data dependency among transactions, known as
\emph{wr-dependency},
\emph{ww-dependency}
and \emph{rw-dependency}.
In a local schedule ${h}$, if ${T_j}$ reads ${T_i}$'s write on ${x}$,
we call it a \emph{read-after-write(wr) dependency} and denote it by ${w_i[x] \rightarrow r_j[x]}$.
Analogically, if ${T_j}$ overwrites ${T_i}$'s write on ${x}$, it is called a \emph{write-after-write(ww) dependency} and denoted by ${w_i[x] \rightarrow w_j[x]}$.
If ${T_i}$ reads ${x}$ before ${T_j}$ writes on ${x}$, it is called a \emph{write-after-read(rw) dependency} and denoted by ${r_i[x] \rightarrow w_j[x]}$.
Based on data dependencies, we can define \emph{commit dependency}. ${T_j}$ has a \emph{commit dependency} on ${T_i}$, written as ${T_i \rightarrow T_j}$, if ${T_j}$ cannot commit prior to ${T_i}$.
More detailed concepts of dependency can be found in \cite{Dependency:conf/sigmod/ChrysanthisR90} \cite{Dependency:conf/sigmod/BilirisDGJR94}
%cite{TODO}

\subsubsection{Relaxation on Correctness Criteria}

Traditional database systems adopt Strict Two-Phase Locking (S2PL) \cite{DBLP:conf/vldb/Raz92} to ensure serializability and recoverability.
Strictness implies that a transaction cannot read a previous write by another transaction that has not been committed yet.
Strictness is not a necessary condition for a correct schedule.
Although it simplifies the implementation of a database system, it sacrifices the concurrency of transaction processing.

%For instance, the schedule ${H_1}$ of Fig. \ref{fig:strict_example} is serializable and strict.
%(The data dependencies include ${r_1[x] \rightarrow w_3[x]}$, ${w_1[x] \rightarrow r_2[y]}$, ${r_2[y] \rightarrow w_3[x]}$, which are not cyclical.)
In contrast, ${H_2}$ in Fig. \ref{fig:non_strict_example} is serializable but not strict.
As we can see, there are three records ${x}$, ${y}$, ${z}$, residing on ${s_1}$, ${s_2}$, ${s_3}$ respectively.
${T_1}$ writes ${y}$ and ${x}$.
${T_2}$ reads ${T_1}$'s write on ${x}$ before ${T_1}$ commits.
Transaction ${T_3}$ overwrites ${T_2}$'s write before ${T_2}$ commits.
By violating strictness, ${H_2}$  enables a higher degree of concurrency.


\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.8]{figure/schedule_non_strict.pdf}}
  \caption{A non-strict but serializabile schedule ${H_2}$}
  \label{fig:non_strict_example}
\end{figure}

\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.8]{figure/schedule_not_serializabile.pdf}}
  \caption{Schedule ${H_3}$, ${T_1}$ abort due to non-serializabile}
  \label{fig:schedule_abort_example}
\end{figure}

\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.8]{figure/schedule_not_recoverable.pdf}}
  \caption{Schedule ${H_4}$, ${T_2}$ commit ahead ${T_1}$, non-recoverable anomaly}
  \label{fig:schedule_not_recoverable}
\end{figure}


The drawback of strictness is further amplified by replication and commit protocols in a GDDB.
The commit of a transaction in a GDDB usually involves a lot of work, including multiple rounds of communication across the WAN.
As strictness requires a transaction to hold locks until it finishes committing, this means a substantially lengthened lock holding time.
Lengthened lock holding time can severely hurt the performance of distributed transactions.
Therefore, we are inclined to embrace a non-strict scheduler.

Relaxation on strictness will, however, complicate the recovery mechanism.
In a traditional recovery mechanism, such as ARIES, the dependencies among transactions completely comply with their logs' persisting order.
Log order guarantees the recoverability of scheduling, which requires that a transaction should not commit prior to the transactions it depends on (in terms of commit dependency).
When strictness no longer holds, we need other tactics to enforce recoverability, which may incur additional overheads.
When both serializability and recoverability (not necessarily strictness) are ensured, we regard a schedule correct.
%In the next section, we will introduce our design to solve recoverability problem.
%Our correctness criteria for lock violation are both serializability and recoverability, but not including strictness.

\subsection{Lock Violation and Dependency Tracing}

Lock violation is a general technique to enable a non-strict scheduler.
Its basic idea is to allow a transaction to speculatively access data locked by other transactions.
If such speculative data accesses cause a problem, the system uses a mechanism to rectify it.

For lock violation to be correct, it should first preserve serializability.
Considering the schedule ${H_3}$ in Fig. \ref{fig:schedule_abort_example},
it contains three data dependencies:

\begin{center}
${w_3[x] \rightarrow _s w_1[x]}$,
${w_1[y] \rightarrow _s r_2[y]}$
${r_2[z] \rightarrow _s w_3[z]}$
\end{center}

This leads to a circle ${T_1 \rightarrow T_2 \rightarrow T_3 \rightarrow T_1}$, which makes the schedule non-serializable.
${H_3}$ is not possible if we apply S2PL.
It becomes possible when lock violation is permitted -- we allow ${T_2}$ to read from uncommitted ${T_1}$, and ${T_1}$ to overwrite uncommitted ${T_3}$.
Therefore, to preserve serializability, we need to prevent the data dependencies from forming a dependency cycle.
Many techniques can be adopted to achieve this, including the \emph{wait-die} strategy mentioned in the related work.

Secondly, a schedule generated by lock violation must be recoverable.
In the schedule ${H_4}$ in Fig.   \ref{fig:schedule_not_recoverable}, due to lock violation,
${T_2}$ reads  ${T_1}$'s write and commits before ${T_1}$.
In this case, if ${T_1}$ decides to abort later, it is no longer possible to revert ${T_2}$.
Therefore, ${H_4}$ is not a recoverable schedule.
To ensure recoverability, we need to trace the commit dependencies among transactions, and force the commit order to comply with the commit dependencies.
If we know that ${T_2}$ depends on ${T_1}$, we can hold ${T_2}$'s commit request until ${T_1}$ finishes.
If ${T_1}$ decides to abort, we abort ${T_2}$ too.
This behavior is known as \emph{cascade abort}.
Cascade abort can be caused by a deterministic abort or a non-deterministic abort.

In summary, dependencies among transactions need to be somehow traced when lock violation is in use, to ensure serializability and recoverability.

\section{Design of DLV}
\label{sec:implement}

In this section, we present our design of Distributed Lock Violation (DLV).

\subsection {Timing of Lock Violation}


In a distributed transaction, $TM$ assigns work to $RM$. Once the work is done, $TM$ applies 2PC to end the transaction.
In 2PC, both $TM$ and $RM$ need to synchronize with their replicas, to make sure that node failures will not corrupt the data.
Synchronization usually takes a long time, especially when the replicas are remotely located.
DLV aims to shorten the lock holding time through lock violation.
In a GDDB, lock holding time can be significantly shortened, if we can violate locks before data synchronization starts.

We classify lock violation into two types, early lock violation (or early violation for short) and late lock violation (or late violation for short).
In early violation,  we allow a transaction's locks to be violated before its serial order can be determined.
In late violation,  we allow a transacation's locks to be violated after its serial order is determined.
%Suppose there are two transactions $T_i$ and $T_j$.
%In a global serializable schedule $H = ... op_i(x) ... op_j(x)$,
%$op_i(x)$ and $op_j(x)$ are $T_i$ and $T_j$'s operations on $x$ respectively.
%And $op_j(x)$ violates $op_i(x)$'s lock on $x$.
%If any operation except the final complete one from $T_i$ is included in $H$ and ${T_i}$ would not abort deterministically,   this lock violation action is late lock violation.
%Correspondingly, if some access operations from  $T_i$ do not exist in $H$, i.e., some ongoing operations have not been scheduled and if $T_i$ can prevent deterministic abort is uncertain, this lock violation action is early lock violation.
%If all the lock violation actions produced by a scheduler are late violation actions, the scheduler is a late lock violation scheduler.
%Otherwise, if some early lock violation action exists, then the scheduler is early lock violation.


More specifically, when two-phase commit is adopted, there are several occasions to perform lock violation.
We classify the timing of lock violation into four categories:

\emph{DLV0}:
Once a transaction finishes a read or write operation, other transactions can immediately violate the lock.
In other words, a transaction can violate a lock at any time.
In this case, serializability needs to be ensured by dependency tracing but not locking.

\emph{DLV1}:
After an ${RM}$ of a distributed transaction finishes its data processing operations on the local node, but before it persists its `prepare commit' state, other transactions can violate this transaction's lock.
In this case, although locking can ensure the serializability of a local schedule, it cannot guarantee the global serializability, because some ${RM}$s may perform deterministic abort.
This is especially true for NDP transactions.

\emph{DLV2}:
When a transaction has entered the second phase of 2PC and received the decision made by the ${TM}$ to commit the transaction, it allows other transactions to violate its locks.
In this case, global serializability can be ensured by locking. Therefore, lock violation does not need to worry about serializability.

\emph{DLV1x}:
This is a variant of DLV1.
Before lock violation is enabled, ${TM}$ performs a serializability test, in which it communicates with all ${RM}$.
If all ${RM}$ agree to commit, the test will be passed, and lock violation will be enabled.
In this case, global serializability can be guaranteed too. And it can perform lock violation earlier than DLV2.
However, this may require an additional message round trip for a NDP transaction.
Fortunately, this message round trip can overlap with the 2PC and replication message flows.

In a GDDB, as this message round trip does not occur between geo-replicated nodes, it is not expensive.
%An DP transaction can combine these messages with the last operations' messages.

\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.50]{figure/lock_violation_time.pdf}}
  \caption
  {Timing of enabling lock violation}
\label{fig:lock_violation_time}
\end{figure}

Fig.~\ref{fig:lock_violation_time} illustrates the different timings of lock violation.
DLV1x adds a serializability test message round trip to the 2PC message flow.
%{change begin}
In this round trip, a \emph{RM} responds \emph{Violate Vote Yes} if it has executed all its access successfully.
This message promise that the \emph{RM}: 1. It will not run any more access actions; 2. if it adds all its access action into the local history, there is no serializability violation.
%{change end}
\emph{TM} collects \emph{RM}'s \emph{Violate Vote Yes} messages and send \emph{Violate Enable} message to notify \emph{RMs} makes their locks violatable.
Technically, we can merge this message round trip with other data access or 2PC messages to save cost.
As a result, DLV1x and DLV2 become the same thing for DP transactions.


We can infer that DLV0 and DLV1 are early violation, and DLV1x and DLV2 are late violation.
Early violation allows us to violate lock earlier, so as we can harness more concurrency. However, there are a few prices it needs to pay.

First, when early violation is performed, we can no longer rely on locking to ensure serializability. This has been illustrated by ${H_3}$ in Fig.~\ref{fig:schedule_abort_example}.
Therefore, early violation has to resort to other measures, such as data dependency tracing, to ensure serializability.
In contrast, late violation is safe on serializability.
We define a transaction's \emph{safe violation time} as the time interval in which its locks can be violated without breaking serializability.
As illustrated by Fig. \ref{fig:lock_violation_safe},
for early violation, there is no safe violation time, as there is no way to determine when lock violation can be safe, unless it performs a serializability test as DLV1x does.
%Take Fig.\ref{fig:lock_violation_safe} as an example,
%a series of transactions ${T_1, T_2, ... T_n}$ write ${x}$ and ${y}$.
%In lock violation cases, ${w_2[x]w_2[y]... w_{n}[x]w_{n}[y]}$ are write operations after lock violation.
%The dependency among ${T_1... T_n}$ may create a circular dependency in early lock violation.
%But in safe lock violation time of late violation, lock violation cannot lead to this cyclic dependencies.

Second, early violation may face a much higher abort rate due to increased chance of serializability violation and cascade abort.
%Section \ref{sec:deadlock_handling} has shown a case of how early lock violation may lead to non-serializable schedules.
In late lock violation, only non-deterministic aborts can cause cascade abort, as no lock can be violated before a deterministic abort.
In early lock violation, all types of aborts can cause cascade abort.

Third, if early violation relies on dependency tracing to ensure serializability, it will incur more overheads.
Whether early or late violation is adopted, we need to trace the commit dependencies among transactions to ensure the commit order (or recoverability).
However, early violation needs to trace all \emph{rw, ww, wr} dependencies, while late violation only needs to trace \emph{wr} dependencies.


\begin{figure}[tbp]
  \centerline{\includegraphics[scale=0.5]{figure/lock_violation_safe.pdf}}
  \caption
  {The green dash line shows the safe violation time of late violation.
  Early lock violation has no safe violation time.
  The italicized text shows the operation after lock violation actions}
\label{fig:lock_violation_safe}
\end{figure}

\subsection{Dependency Tracing}
As discussed previously, when lock violation is in use,
the scheduler must trace commit dependencies to ensure recoverability.
If early lock violation is adopted, the scheduler needs to trace more dependencies (including all \emph{rw, wr, ww}-dependencies) to ensure serializability.
(For late lock violation, we only need to ensure recoverability.
It will be enough to trace \emph{wr} dependencies only.)

DLV applies the register-and-report method~\cite{HeckatonMVCC:journals/pvldb/LarsonBDFPZ11} to trace commit dependencies.
Each transaction maintains an in-dependency count ${in}$ on each of its ${RM}$s, which records the number of transactions it depends on that ${RM}$.
Each transaction also maintains an out-dependency set  ${out}$ on each of its ${RM}$s, which records all the transactions depending on it on that ${RM}$.
When a transaction ${T}$ violates another transaction ${S}$'s lock on a ${RM}$,
DLV would register the commit dependency by adding ${T}$ to the corresponding ${out}$ set of ${S}$ and incrementing the corresponding ${in}$ of ${T}$ by one.
A ${RM}$ will not vote to commit (or prepare commit) if its ${in}$ dependency count is greater than 0, suggesting that the DB has not yet committed some of its in-dependency transactions.
When a transaction aborts, it notifies all its out-dependency transactions to abort (cascade abort) by setting their ${in}$ dependency counts to a negative value.
(If a transaction finds that one of its ${in}$ dependency counts is negative, it will abort automatically.)
When a transaction commits, it will traverse its ${out}$ sets and decrease the corresponding ${in}$ value of each transaction in the ${out}$ set by one.

Note that each $RM$ node independently maintain the dependency information locally.
We do not allow a ${RM}$ to enter an undecidable state (e.g., the `prepare commit' state) before its in-dependency count ${in}$ becomes zero.

If a transaction's ${in}$ value on a ${RM}$ is greater than 0, it implies that not all the transactions it depends on has committed.
Then, we can guarantee that this ${RM}$ will not enter the uncertain ``prepare commit'' state.
%its ${RM}$ state not neither decided(``committed'' or    ``aborted'') or uncertain( ``prepared'').
%If a transaction's ${out}$ is not empty, there must be some transactions that has violated its locks.
%All the dependent outer transactions are also neither decided or uncertain.
When a node fails, all the un-prepared ${RM}$s on the node can simply vote to rollback their transactions, without referring to the dependency information.
In this case, both the ${in}$ values and the ${out}$ sets on the node become useless.
Therefore, the system only needs to preserve the dependency information in memory without persisting it to stable storage.


\subsection{Cascade Abort Handling}
When a cascade abort occurs,
we need to undo a number of transactions.
(When late lock violation is in use, cascade abort can only be triggered by a node failure.)
In case of failure, traditional DB systems use undo logs to cancel out a transaction's write operations.
Undo becomes a bit tricky in a distributed environment.

For a centralized DB, its scheduler can utilize the chronological order of the logs to perform undo.
During system recovery, the database can play the undo logs in reverse order, just as what ARIES \cite{ARIES:journals/tods/MohanHLPS92} does.
For a distributed DB, a global undo order cannot be easily achieved.
%There is no global chronological log order, and the existence of partial failure makes it is hard to guarantee the undo order only by local log order.
%If possible, the performance can be unacceptable because the scheduler must backtrace many log records when normal transaction processing rather than system recovery.
%If the lock violation scheduler undoes write by the wrong order,
If undo is performed locally by each transaction, it may produce anomalies.
Consider the following example. Suppose two tuples $x$ and $y$ are located at two nodes.
Two distributed transactions $T_1$ and $T_2$ access both $x$ and $y$, and result in a global schedule:

\begin{center}
${H_5 = ...w_1[x]w_1[y]r_2[x]w_2[y]a_1a_2}$
\end{center}

When a node fails, ${T_1}$ aborts, which forces ${T_2}$ to abort too.
The aborts trigger undo operations, which extend ${H_5}$ to ${exp(H_5)}$,
in which ${w^-_i[x]}$ denotes that ${T_i}$ undoes its write on ${x}$.

\begin{center}
  ${exp(H_5) =  w_1[x]w_1[y]r_2[x] w_2[y]}$
  ${w^-_1[x]w^-_1[y]  c_1 w^-_2[y]c_2}$
\end{center}


\begin{table}[tbp]
  \centering
  \caption{local schdeule $h_1$ and $h_2$, $x$ and $y$'s values, undo log after the execution of ${exp(H_5)}$}
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
  \hline
steps & $h_1$ & $x$ & $h_2$ & $y$ & undo   \\
  \hline
  \hline
 1& $w_1[x=1]$ & 1 & &  0 & x=0  \\
  \hline
  2& & 1 & $w_1[y=1]$ & 1 & y=0   \\
  \hline
3 & $r_2[x]$ & 1 & & 1 &    \\

  \hline
 4 & failure  & 1 & & 1 &  \\
  \hline
 5& & 1 &   $w_2[y=2]$ & 2 & y=1  \\
  \hline
6  & $w^-_1[x=0]$ & 0 && 2 &   \\
  \hline
7 & & 0 & $w^-_1[y=0]$ & 0 &   \\
  \hline


8  & $c_1$ & 0 &$c_1$& 0 &   \\
  \hline
9 & & 0 &  $w^-_2[y=1]$& 1 &   \\
  \hline
10 & $c_2$ & 0 &$c_2$& 1 &  \\
  \hline
  \end{tabular}

\label{tbl:x_y_vlues}
\end{table}

In $exp(H_5)$, the two transaction perform undo independently. This results in an anomaly.
Table~\ref{tbl:x_y_vlues} shows the local schedules of $exp(H_5)$, i.e., ${h_1}$ and  ${h_2}$, and how ${x}$ and ${y}$ change as we carry out the operations.
(Suppose the initial values of ${x}$ and ${y}$ are both 0.)
In step 4, the node hosting ${x}$ fails and restarts.
As we can see, after both ${T_1}$ and ${T_2}$ abort, the value of ${y}$ becomes 1, which is incorrect.

To ensure correctness, we have to follow the reverse order of the write operations to perform undo.
For ${H_5}$, a correct undo schedule should be:
\begin{center}
${exp^*(H_5) = w_1[x]w_1[y]r_2[x]w_2[y]w^-_2[y]c_2w^-_1[y]w^-_1[x]c_1}$
\end{center}

%This problem is intrinsic.
To tackle this problem, we need a complex algorithm, such as SOT \cite{UnifyCR:journals/is/AlonsoVABASW94}.
To reduce complexity, DLV adopts the no-steal policy in logging.
The no-steal policy forbids the system from writing uncommitted data to permanent storages.
As a drawback, it may consume more memory space.
Considering that today's database servers usually have large RAM, this is no longer a big concern.
Based on this design, we need no undo logs anymore. If a transaction aborts, we only need to discard its uncommitted data in memory.
The no-steal policy has another advantage in GDDB.
Using No-steal, a transaction can push the work of data synchronization to the commit phase.
Thus, through lock violation, we can exclude data synchronization completely from the lock holding duration.

When multiple concurrent transactions modify the same data, this data can have multiple versions in memory.
Therefore, DLV needs to maintain a version list for each data item.
There is only one version for each data item in the permanent storage, which is the newest committed version.

Fig.~\ref{fig:versions_example} illustrates why cascade abort only need to consider $wr$ dependencies but not $ww$ dependencies. %how DLV handle $ww$ dependencies when a transaction aborts.
Suppose a number of transactions accessed two tuples, ${x}$ and ${y}$.
The green rectangles represent the uncommitted versions of the data in the version lists, and the red ones represent the committed versions.
We can see that although there is a ${ww}$ dependency ${w_6[x] \rightarrow w_4[x]}$,
the abort of $T_4$ does not require ${T_6}$ to abort.
\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[${H_a}$]
  {
    \includegraphics[scale=1.0] {figure/version1} \label{fig:versions_a}}
    \captionsetup[subfigure]{margin={0cm,0cm}
  }
  \subfloat[\small ${H_b}$]
  {
    \includegraphics[scale=1.0]{figure/version2} \label{fig:versions_b}
  }
    \captionsetup[subfigure]{margin={0cm,0cm}
  }
  \subfloat[\small ${H_c}$]
  {
    \includegraphics[scale=1.0] {figure/version3} \label{fig:versions_c}}
    \captionsetup[subfigure]{margin={0cm,0cm}}
    \subfloat[\small ${H_d}$]
      { \includegraphics[scale=1.0]{figure/version4} \label{fig:versions_d}
  }
  \caption{\emph{ww}-dependencies are not required for recovery.
  ${x_i}$ represents the version of $x$ created by ${T_i}$.
 Then, $w_j[x_i]$ represents that ${T_j}$ overwrites the write of ${T_i}$ on $x$. In the history, ${H_a = w_1[x_0]w_1[y_0]c_1w_2[x_1]w_3[x_2]w_3[y_1]w_4[x_3]}$, 
 ${H_b = H_a c_2r_5[y_3]w_6[x_4]}$,
 ${H_c = H_b a_3a_5}$, 
 ${H_d = H_c c_4r_6[y_1]c_6}$
}
\label{fig:versions_example}
\end{figure}


\subsection {Deadlock Handling}
\label{sec:deadlock_handling}
When we apply lock violation, deadlock can occur.
There are various approaches to handle deadlock.
%We choose two typical ones to discuss how a lock violation scheduler can adapt to the deadlock handle mechanism.
Deadlock detection is the most widely used approach in a centralized DB.
Deadlock detection needs to maintain a waits-for graph (WFG).
In a distributed environment, maintaining a WFG is expensive.
Another approach to handling deadlock is deadlock prevention, which is simpler but more restrictive.
Different deadlock handling techniques may suit different lock violation methods.
For instance, early violation may work better with deadlock detection, while late violation may work better with deadlock prevention.
% \emph{path pushing} approach.
%For early violation, not only the locking wait transactions but also the lock violation transactions would contribute edges to WFG.
%Additional edges in WFG at any time, in turn, lead more likely deadlock and a greater abort rate.
%The late violation would not violate serializability, and
%deadlock detection need not trace lock violation action.

%Late lock violation adopts deadlock prevention.

Out implementation of deadlock prevention uses the \emph{wait-die} protocol to prevent deadlocks and preserve serializability.
A transaction is assigned a unique timestamp when it starts.
(This does not require a centralized timestamp allocator.
Each node can generate a unique timestamp for its transactions by combining its local clock time and node id.)
Then, conflicting transactions can be ordered by their timestamps.
Following the wait-die protocol, a transaction will wait if it attempts to access a data item locked by a transaction with a larger timestamp.
It will abort, if the data item is locked by a transaction with a smaller timestamp.
Only allowing a transaction to violate a lock with a larger transaction id can guarantee that the data dependencies are acyclic.

%Similar deadlock detection approach,
%early lock violation scheduler must apply the \emph{wait-die} protocol for violation action to ensure serializability, but it is not necessary for late violation.

Early lock violation may suffer a higher abort rate, if we adopt lock prevention.
Given a set of transactions ${T_1, T_2... T_n}$, their IDs follows a total order, ${T_1 < T_2 < ... < T_n}$.
Their dependencies are in the form ${T_1 \rightarrow T_2 ... \rightarrow T_n}$.
In \emph{wait-die}, ${T_2, ..., T_n}$ must abort due to lock violation's wait-die policy(a larger transaction id must abort when encountered conflict lock of a smaller transaction id) even there is no serializability violation.

In the same time window from transaction ${T_1}$'s start to its end, only transaction ${T_1}$ can commit.
In this case, violation scheduler performance is the same as the S2PL scheduler.
If the scheduler took the deadlock detection approach, transaction ${T_2, ... T_n}$ would not necessarily abort because there was no deadlock.
Early lock violation performance using deadlock detection for this case may be better than deadlock prevention ones.
In the late lock violation case, dependency ${T_1 \rightarrow T_2 , ... ,T_n}$ would not contribute to non-serializability.
These dependencies are not necessarily traced by deadlock detection or be test by the wait-die policy.
This late violation case can get better performance since ${T_2,..., T_n}$ can commit if there is no system failure.

\section{Experiments}
\label{sec:experiment}
We developed a GDDB engine to evaluate the performance of \emph{DLV}.
We conducted extensive experiments to compare different types of \emph{DLV} (DLV0, DLV1, DLV2 and DLV1x) against the traditional S2PL approach.
The goal was to understand how good \emph{DLV} is and what implementation of \emph{DLV} can yield the best performance. 

\subsection{Experimental Setting}
\label{subsec:exp_setting}

Our experiments were conducted in Ali-Cloud.
In total, 12 servers were used.
Each server was equipped with 12 virtual CPU cores of 2.5GHz and a 48GiB RAM.
The OS was Ubuntu 18.04.
The database partitioned its data into four shards.
Each shard had three replicas spread across three AZs,
located in Heyuan (South China), Hangzhou (East China) and Zhangjiakou (North China) respectively.
Every AZ had a full copy of each shard of data.
The internal network bandwidth in each AZ was 1Gbps.
We used one of the servers as the client node dedicated to issuing transaction requests.
In the experiments, if a transaction aborted due to confliction, it would retry in 2 seconds.
We used the TPC-C and YCSB benchmarks to perform the evaluation.


TPC-C~\cite{TPCC:conf/tpctc/NambiarWMTLCM11} models a real-world scenario, in which a company sells products through multiple warehouses in different districts, and customers order products and pay bills.
In our version of TPC-C, we partitioned the data mainly by the warehouse IDs.
The item table was not partitioned, but replicated across all the shards.
Such a DB design enabled us to achieve the best performance.
As our purpose was to evaluate the performance of distributed transactions,
we made all the transactions distributed by enforcing each transaction to order items from warehouses located at different nodes.
We excluded the think time of TPC-C and only measured the performance of the NewOrder transactions.


YCSB~\cite{YCSB:conf/cloud/CooperSTRS10} was originally designed to evaluate NoSQL databases.
Its transactions are relatively simple.
Each YCSB transaction accesses nearly ten rows of data, which follow a Zipfian distribution.
By adjusting the skewness of the Zipfian (i.e., the parameter \emph{theta}), we can customize the degree of contention.
We partitioned the YCSB data by the primary key of the main table.
To make all transactions distributed, we forced each transaction to access at least two shards.

We evaluation the performance by TPM(the number of transactions committed in each minute).


\subsection{Deadlock Detection vs Deadlock Prevention}

To handle deadlock, DLV faces two options, deadlock detection or deadlock prevention, as discussed in Section~\ref{sec:deadlock_handling}.
It is not obvious which approach works better for DLV. 
Therefore, our first set of experiments was to compare the two approaches for handling deadlocks.
We implemented \emph{wait-die} as the deadlock prevention approach.
When the \emph{wait-die} policy is employed, blocking will be rare, aborts will be the main obstacle to performance.
For deadlock detection, we implemented a de-centralized path-pushing deadlock detector\cite{Deadlock:journals/computer/Singhal89}.
%When using the deadlock detection algorithm,  blocking on locks is the most performance restriction if the deadlock is infrequent.

We applied deadlock detection and deadlock prevention to all the DLV variants as well as S2PL. 
We evaluated these approaches using YCSB.
We increased the number of user terminals until the throughput of the database reach its maximum.
The results of the experiments are shown in Fig.~\ref{fig:ycsb_deadlock} 



\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[YCSB TPM]
      { \includegraphics[scale=0.35] {figure/plot_ycsb_add_Terminal_Terminal_TPM_gather} \label{fig:ycsb_add_terminal_gathered:tpm}}

      \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[YCSB abort rate]
      { \includegraphics[scale=0.35]{figure/plot_ycsb_add_Terminal_Terminal_Abort_gather} \label{fig:ycsb_add_terminal_gathered:abort}}


            

\caption{Deadlock Detection vs Deadlock Prevention: impact of varying workload
($(d)$ indicates adoption of deadlock detection. $(p)$ indicates adoption of deadlock prevention. ) }
\label{fig:ycsb_deadlock}
\end{figure}

      
As we can see, there was no dominant winner. It is quite clear that deadlock detection works better for early lock violation, i.e., DLV0 and DLV1, 
and deadlock prevention works better for late lock violation, i.e., DLV1x and DLV2. This is consistent with our analysis in Section~\ref{sec:deadlock_handling}.
Deadlock detection can be expensive when there is a high degree of contention. In contrast, deadlock prevention will incur a high abort rate to early lock violation.
We can see that if deadlock prevention is used, DLV0 and DLV1 cannot even outperform S2PL. 

Deadlock detection does not scale well when the system is saturated.
As we can see, early lock violation could not scale to more than 200 terminals, but late lock violation could.

Nevertheless, a number of the DLV variants can outperform S2PL significantly. This means that lock violation can improve the performance of a GDDB.

Based on this results, in the rest of the evaluation, we applied deadlock detection to DLV0 and DLV1, and deadlock prevention to DLV1, DLV2 and S2PL respectively,
as such a configuration can maximize the performance of all the competing approaches.


\subsection{Impact of Geo-replication}

In the second set of experiments, we evaluated how geo-replication affects the performance of transaction processing.
We simulated geo-replication in a single AZ.
Namely, we put all replicas in the same AZ and artificially increased the replicas' communication latency.
We used the YCSB workload, in which we set the size of the data to 400,000 rows and the skewness (theta) to 0.2.
Fig.~\ref{fig:new_order_add_log_cost} shows how the throughput and the abort rate changed with the increased replication latency.
Geo-replication has a great impact on performance. The higher the replication latency, the lower the throughput of transaction processing.

We can also see that the DLVs performed significantly better than traditional S2PL in the experiments.
DLV0, DLV1 and DLV1x outperformed S2PL by 2-5 times when the replication latency is high.
While DLV2 slightly outperformed S2PL too, it was inferior to other DLVs.
This is because DLV2 does not violate locks early enough, and its lock duration overlaps with data synchronization among geo-replicas.
As DLV1, DLV2 and S2PL adopted the wait-die protocol, transactions chose to abort when confronted with serious contention.
Therefore, the abort rates measure how the performance was affected by contention.
The result shows that DLV1x could deal with contention better than DLV2 and S2PL .
%As they release locks earlier than S2PL, they are subject to less contention than S2PL. (DLV1x releases locks earlier than DLV2.)
%While DLV0 and DLV1 perform early lock violation, they suffer from an increased chance of serializability breach and cascade aborts.
%Therefore, their abort rates were also high in the experiments.

\begin{figure}[tbp]
  %cloud setting
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[]
      { \includegraphics[scale=0.35] {figure/plot_ycsb_add_LogForceT_LogForceT_TPM_gather} \label{fig:new_order_add_log_cost:tpm}}

  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[]
      { \includegraphics[scale=0.35]{figure/plot_ycsb_add_LogForceT_LogForceT_Abort_gather} \label{fig:new_order_add_log_cost:abort}}

\caption{Impact of Geo-distance on Performance}
\label{fig:new_order_add_log_cost}
\end{figure}


\subsection{Impact of Contention}

Our third set of experiments aimed to evaluate how the degree of contention affects transaction processing performance.
We used both the TPC-C workload and the YCSB workload.
We ran all the experiments in a real geo-replication environment described in Section~\ref{subsec:exp_setting}.
We adopted the gathered mode in the experiments, which assumes that all replica leaders co-locate in the same AZ.


\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
      { \includegraphics[scale=0.35] {figure/plot_tpcc_neworder_add_Warehouse_Warehouse_TPM_gather} \label{fig:plot_tpcc_neworder_add_Warehouse_Warehouse_gather:tpm}}
  \captionsetup[subfigure]{margin={0cm,0cm}}
\caption{Impact of Warehouse number on Performance (TPC-C)}
\label{fig:plot_tpcc_neworder_add_Warehouse_Warehouse_gather}
\end{figure}

\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
      { \includegraphics[scale=0.35] {figure/plot_tpcc_neworder_add_HotItem_HotItem_TPM_gather} \label{fig:plot_tpcc_neworder_add_HotItem_HotItem_gather:tpm}}
  \captionsetup[subfigure]{margin={0cm,0cm}}
\caption{Impact of Hot Spot on Performance (TPC-C)}
\label{fig:plot_tpcc_neworder_add_HotItem_HotItem_gather}
\end{figure}

In the experiments of TPC-C, we first fixed the client number of every shard to 100 and varied the warehouse number between 10 to 60.
%The smaller the number of warehouses, the higher the degree of contention.
Fig.~\ref{fig:plot_tpcc_neworder_add_Warehouse_Warehouse_gather} gives the results.
%As we can see, almost all DLVs outperformed S2PL. DLV1 and DLV1x showed the best overall performance. It outperformed S2PL by up to 2-5 times.
Then, we fixed the number of warehouses to 40, and varied the percent of the transactions accessing hot tuples. (There were 4 hot tuples in total.)
Fig.~\ref{fig:plot_tpcc_neworder_add_HotItem_HotItem_gather} shows the results.

From Fig.~\ref{fig:plot_tpcc_neworder_add_Warehouse_Warehouse_gather} and
Fig.~\ref{fig:plot_tpcc_neworder_add_HotItem_HotItem_gather},
we can see that contention had a big impact on performance. When the degree of contention decreased, the throughput rose quickly.
The DLVs performed better than S2PL in general, as lock violation had shortened their lock blocking time, especially when the degree of contention is high.
However, the different DlVs demonstrated different performance characteristics. 
While DLV0 and DLV1 performed well when there is less contention, their performance dropped when the contention intensified.
This is because contention increases their chance of encountering deadlocks.
In contrast, DLV1x outperformed the other approaches constantly, as it was less affected by deadlocks.
%DLV's performance is three times higher than that of S2PL when the possibility of the transaction accessing hotspot reaches 0.8.
%DLV0 and DLV1 do not improve throughput a great because it has a more abort rate than S2PL.
%Among the DLVs, DLV1x performed the best, as it suffered less from blocking conflicts locks and cascade aborts.

\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}
      { \includegraphics[scale=0.35] {figure/plot_ycsb_add_Theta_Theta_TPM_gather} \label{fig:plot_ycsb_add_Theta_Theta_TPM_gather:tpm}}



\caption{Impact of theta on Performance (YCSB)}
\label{fig:plot_ycsb_add_Theta_Theta_TPM_gather}
\end{figure}

In the experiments on YCSB, we fixed the number of clients of every shard to 100.
Then we varied the parameter \emph{theta} (the skewness of the Zipfian distribution) to control the degree of contention.
The larger the \emph{theta}, the more skewed the distribution and the higher the degree of contention.
Fig. ~\ref{fig:plot_ycsb_add_Theta_Theta_TPM_gather} shows how the throughput was affected by the changing skewness.
The results also show that contention had a huge impact on performance.
Similar to the results on TPC-C, DLVs outperformed S2PL.
However, different from the results on TPC-C, DLV0 and DLV1 performed as well as DLV1x in YCSB.
This can be attributed to the characteristics of YCSB. As the data and transactions of YCSB are much simpler than TPC-C, DLV0 and DLV1 will be less affected by deadlocks.

\subsection{On Scalability}

We conducted experiments in both the gathered mode and the scattered mode to evaluate distributed transactions' scalability.
In the gathered mode, all the replica leaders are in the same AZ.
The gathered mode is the most common mode, in which servers in the leaders' AZ served the requests mainly, and servers in other AZs are only for the replication purpose.
In the scattered mode, the replica leaders may spread across different AZs.
Large-scale Web applications usually adopt this mode, which makes their service globally available.

We conducted experiments on the TPC-C workload.
Fig. ~\ref{fig:new_order_add_terminal_gathered} shows the performance of distributed transactions on TPC-C workload in the gathered mode.
We fixed the number of warehouses to 40.
Then we gradually increased the number of clients until the system was saturated.
We can see that DLVs outperformed S2PL in general.
The maximum throughput S2PL could achieve around 31,000 TPM (Transactions per Minute),
while the throughput of DLV1x could achieve 59,000 TPM.


Fig. ~\ref{fig:new_order_add_terminal_scattered}  shows the TPC-C evaluation results in the scattered mode.
As the intra-transaction communication in the scattered mode needs to cross AZs, its performance was slightly worse than that of the gathered mode.
Nevertheless, the results exhibit the same trend. DLVs outperformed S2PL significantly.

Among all the variants of DLV, DLV1x demonstrated the most constant performance.

%We also evaluate the throughput on YCSB when increasing the terminal number of each shard.
%Fig. ~\ref{fig:ycsb_add_terminal_gathered} shows the results.
%DLV1x scales better when adding concurrent terminals.
%When the test reaches the maximum number of concurrent terminals, DLV1x is twice as the throughput of S2PL.


\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}

      { \includegraphics[scale=0.35] {figure/plot_tpcc_neworder_add_Terminal_Terminal_TPM_gather} \label{fig:new_order_add_terminal_gathered:tpm}
      
      }

\caption{Performance in Gathered Mode (TPC-C) }
\label{fig:new_order_add_terminal_gathered}
\end{figure}

\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}

      { \includegraphics[scale=0.35] {figure/plot_tpcc_neworder_add_Terminal_Terminal_TPM_scatter} \label{fig:new_order_add_terminal_scattered:tpm}}


\caption{Performance in the Scattered Mode (TPC-C) }
\label{fig:new_order_add_terminal_scattered}
\end{figure}

%change begin
\subsection{Evaluation of Interactive Transactions}
To evaluate the performance of the lock violation on interactive transactions,
we conducted an additional set of experiments on TPC-C, in which each transaction's ${TM}$ interactively accesses data and then enforces a two-phase commit.
Fig \ref{fig:interactive_evaluation} shows the results.
%Transactions throughput goes up with the terminal number increasing.
As mentioned earlier, most interactive transactions are DP transactions.
A DP transaction is determined to be prepared when the \emph{RM}s receive the prepare message.
Therefore, DLV1x performed as well as DLV1 in the experiments, as it can enable lock violation as early as DLV1.


\begin{figure}[tbp]
  \centering
  \captionsetup[subfigure]{margin={0cm,0cm}}

      { \includegraphics[scale=0.35] {figure/plot_interactive__tpcc_neworder_add_Terminal_Terminal_TPM_gather} \label{fig:tpcc_add_terminal_interactive:tpm}}

      \caption{TPCC interactive transaction evaluation}
      \label{fig:interactive_evaluation}
      \end{figure}


\subsection{Evaluation of Cascade Abort}
DLV suffers from cascade abort. In comparison, early lock violation is more vulnerable to cascade abort than
late lock violation.
To evaluate the cost of cascade abort on different approaches of lock violation, we conducted additional experiments on TPC-C, in which the number of warehouses was fixed to 40  and the terminal number to 200.
We only considered and evaluated the effect of deterministic abort.

Fig.\ref{fig:evaluation_cascade_abort} shows the cascade abort rate in comparison with the total abort rate.
%Cascade abort rate is cascade abort transaction number divided by total transaction number.
%On the top of each bar there is the cascade abort rate.
%S2PL, DLV2, and DLV1x have no cascade abort.
Fig.\ref{fig:evaluation_cascade_abort:nonexist_row}
shows the abort rates under normal TPC-C workload.
Fig.\ref{fig:evaluation_cascade_abort:nonexist_row} 
shows the abort rates under a modified TPC-C workload, in which each transaction has 10\% of chance to access a non-existent row and incur an abort. 
 
As we can see, S2PL, DLV2, and DLV1x seldom encounter cascade aborts, no matter whether deadlock detection or deadlock prevention is applied. 
In contrast, there is a significant chance of cascade abort for DLV1 and DLV0, especially when deadlock detection is applied. Deadlock prevention encounters less cascade aborts because it tends to abort transactions earlier, before cascade abort kicks in. The total abort rates incurred by deadlock prevention were actually always higher than those by dead detection.


\begin{figure}[tbp]
  \centering

  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[no transactions access non-exist rows]
      { \includegraphics[scale=0.3] {figure/plot__tpcc_neworder_add_NonExist_0.pdf} \label{fig:evaluation_cascade_abort:without_nonexist_row}}

      \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[10\% transactions access non-exist rows]
      { \includegraphics[scale=0.3]{figure/plot__tpcc_neworder_add_NonExist_10.pdf} \label{fig:evaluation_cascade_abort:nonexist_row}}

\caption{Cascade abort ratio, DD stands  for deadlock detection, and DP stands for deadlock prevention}
\label{fig:evaluation_cascade_abort}
\end{figure}


\subsection{Transactions Latency Evaluation}


\begin{figure}[tbp]
  \centering

  \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[Deadlock detection]
      { \includegraphics[scale=0.3] {figure/tpcc_neworder_add_Terminal_latency_Detection.pdf} \label{fig:evaluation_latency:deadlock_detection}}

      \captionsetup[subfigure]{margin={0cm,0cm}}
  \subfloat[Deadlock prevention]
      { \includegraphics[scale=0.3]{figure/tpcc_neworder_add_Terminal_latency_WaitDie.pdf} \label{fig:evaluation_latency:deadlock_prevention}}

\caption{Transaction Latency}
\label{fig:evaluation_latency}
\end{figure}

DLV cannot directly impact transaction latency.
Although DLV shortens the possible lock blocking time, it must wait for its dependent transactions to commit.
We evaluated transaction latency on TPCC workload. 
The warehouse number was fixed to 40, and the terminal number was set to 10, 100, and 200.
Different from other previous evaluation settings, in this experiment,
the transaction would be immediately retried five times after it aborted without a wait.
Only the average latency of committed transactions are considered.
We can see that transaction latency is mainly affected by the deadlock handling scheme and the load condition.
The latency using deadlock prevention has less latency than using deadlock prevention on high load.
The latency is very similar in the same setting. 

\subsection{Experimental Conclusion}

In conclusion, our experimental evaluation showed that the geo-replication could have a big negative impact on distributed transactions' performance.
Besides the overheads of data synchronization incurred by replication, the prolonged lock holding time is a main contributor to the degraded performance.
We demonstrated that lock violation could be an effective measure to shorten the lock critical time and boost the performance of GDDB.
However, it is important to find the right time to violate the locks, to harness the benefit of lock violation.
For different timing of lock violation, different approaches should be adopted for handling deadlocks.
Our evaluation also showed that late lock violation can be superior to early lock violation in most cases, as it works well with lock prevention, which is less expensive than distributed lock detection.


\section{Conclusion}
\label{sec:conclusion}

This paper discussed the application of lock violation in geo-replicated distributed databases.
Lock violation is not only concerned with the concurrency control mechanism, but it is also related to the modules of recovery and persistence.
Therefore, its adoption requires a holistic redesign of the transaction processor.
In this paper, we proposed such a holistic design and conducted experiments to evaluate its effectiveness.
The results showed that lock violation could boost the performance of a geo-replicated distributed database, especially when the degree of contention is high.
Moreover, we found that not all lock violation approaches can be beneficial. We identified the right design of lock violation, to maximize its effects.


DLV cannot reduce transactions' latencies, while it enables better throughputs.
It can consolidates wait time of transaction execution, especially that in the commit phase.
When there is more idle resource, it is more rewarding to use aggressive lock violation as well as deadlock detection to precisely avoid false-positive abort.
In contrast, when a system reaches its saturation point, the system should switch to more conservative
lock violation to avoid its overheads.
Deciding opportunities to conduct DLV can be an interesting topic for future work.



\bibliographystyle{reference/IEEEtran}
\bibliography{reference/IEEEexample}


\end{document}

